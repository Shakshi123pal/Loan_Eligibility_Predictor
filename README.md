# ğŸ¦ Loan Eligibility Predictor

A machine learning project that predicts whether a loan applicant is eligible for a loan, based on financial and personal information. Built using Python, trained with two models (Logistic Regression and Random Forest), and integrated into a web application using Streamlit.

---

## ğŸ“Œ Problem Statement

Banks and financial institutions need a reliable way to assess whether a loan applicant should be approved or not. This project helps automate that decision-making process using a classification model trained on historical data.

---

## ğŸš€ Project Highlights

- âœ… Built and compared two models: Logistic Regression and Random Forest
- ğŸ“Š Performed thorough Exploratory Data Analysis (EDA) and preprocessing
- ğŸ“¦ Exported the final model using `joblib`
- ğŸŒ Integrated the model into a simple web app using Streamlit
- ğŸ”„ Learning to apply MLOps practices step-by-step (version control, model reuse, deployment)

---

## ğŸ› ï¸ Tech Stack

| Category         | Tools Used                            |
|------------------|----------------------------------------|
| Programming      | Python                                 |
| Data Handling    | Pandas, NumPy                          |
| Visualization    | Matplotlib, Seaborn                    |
| ML Algorithms    | Logistic Regression, Random Forest     |
| Model Saving     | Joblib                                 |
| Deployment       | Streamlit (local, deploy-ready)        |
| Version Control  | Git, GitHub                            |

---

## ğŸ§ª ML Pipeline

1. **Data Preprocessing**
   - Missing values, label encoding, feature selection

2. **EDA**
   - Analysis based on credit history, income, loan amount, etc.

3. **Modeling**
   - Compared Logistic Regression and Random Forest
   - Evaluated with accuracy, precision, recall, and confusion matrix

4. **Model Saving**
   - Saved best-performing model (`loan_model.pkl`) using `joblib`

5. **Web App Integration**
   - Created `app.py` with user input form using Streamlit
   - Model predicts eligibility instantly

---

## ğŸ“‚ Project Structure

Loan_Eligibility_Predictor/
â”‚
â”œâ”€â”€ app.py # Streamlit web app
â”œâ”€â”€ loan_model.pkl # Saved model
â”œâ”€â”€ loan_prediction.ipynb # Model training & comparison
â”œâ”€â”€ Loan_prediction_eda_part.ipynb # Data analysis
â”œâ”€â”€ loan_prediction_data_understanding.py.ipynb
â”œâ”€â”€ README.md # Project documentation
â””â”€â”€ .gitignore


---

## ğŸ“ˆ Results & Insights

- **Random Forest** performed better than Logistic Regression (mention your accuracy/F1-score if available)
- **Credit History**, **Income**, and **Loan Amount** were key features affecting approval
- Visualizations showed a clear relationship between loan status and applicant financial profiles

---

## ğŸ’» How to Run the Project Locally

1. **Clone the repo**

```bash
git clone https://github.com/Shakshi123pal/Loan_Eligibility_Predictor.git
cd Loan_Eligibility_Predictor


2. Install dependencies:
pip install -r requirements.txt


3.Run the Streamlit app:
streamlit run app.py




## ğŸ“ˆ Results & Insights

### Model Performance Summary

| Model               | Accuracy | Precision (Class 0) | Recall (Class 0) | F1-score (Class 0) | Precision (Class 1) | Recall (Class 1) | F1-score (Class 1) |
|---------------------|----------|---------------------|------------------|--------------------|---------------------|------------------|--------------------|
| **Random Forest**    | 82.9%    | 0.77                | 0.63             | 0.70               | 0.85                | 0.92             | 0.88               |
| **Logistic Regression** | 85.4%    | 0.95                | 0.55             | 0.70               | 0.83                | 0.99             | 0.90               |

### Detailed Insights

- The **Logistic Regression** model achieved slightly higher accuracy (85.4%) compared to Random Forest (82.9%).
- Logistic Regression has a very high recall (0.99) for the positive class (eligible applicants), meaning it correctly identifies most eligible loan applicants.
- Random Forest shows a better balance between precision and recall for both classes.
- Confusion matrices show:
  - Logistic Regression had fewer false negatives (missed eligible applicants) but more false positives.
  - Random Forest had more balanced errors across both classes.

### Interpretation

These results indicate that Logistic Regression is more sensitive in identifying eligible applicants (good for minimizing missed opportunities), while Random Forest offers a more balanced prediction performance.


